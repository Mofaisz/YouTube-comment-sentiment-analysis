{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd0a08f-70a4-4e9f-a437-492ce278da65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@dhruvrathee</td>\n",
       "      <td>2024-03-15T15:46:22Z</td>\n",
       "      <td>2024-03-16T12:09:00Z</td>\n",
       "      <td>8353</td>\n",
       "      <td>Today, is 10th Day of Fast for Sonam Wangchuk....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@KrishnaDas-vc6vo</td>\n",
       "      <td>2024-03-17T11:16:05Z</td>\n",
       "      <td>2024-03-17T11:16:05Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Why you are silent on sandeshkhali BDSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@PremiumCar78</td>\n",
       "      <td>2024-03-17T11:15:58Z</td>\n",
       "      <td>2024-03-17T11:15:58Z</td>\n",
       "      <td>0</td>\n",
       "      <td>BJP walo ki ulti ginti shuru. Ye andhbakto ko ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VillageCookingChannelTelangana</td>\n",
       "      <td>2024-03-17T11:15:48Z</td>\n",
       "      <td>2024-03-17T11:15:48Z</td>\n",
       "      <td>0</td>\n",
       "      <td>i don&amp;#39;t have words to say how much ur grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@hafizfurqan2565</td>\n",
       "      <td>2024-03-17T11:15:44Z</td>\n",
       "      <td>2024-03-17T11:15:44Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Very good information garet job brother ‚ù§‚ù§‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>@Universalmusic5</td>\n",
       "      <td>2024-03-17T10:46:21Z</td>\n",
       "      <td>2024-03-17T10:46:21Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Bhai pata nahi kyu youTube inki video ko trend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@masoomali66</td>\n",
       "      <td>2024-03-17T10:46:06Z</td>\n",
       "      <td>2024-03-17T10:46:06Z</td>\n",
       "      <td>0</td>\n",
       "      <td>electoral bonds par video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>@dhirajthorat6301</td>\n",
       "      <td>2024-03-17T10:45:40Z</td>\n",
       "      <td>2024-03-17T10:45:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Bhai Modi ke pas. black magic..hey...o..kisi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@AjadKhan-wh3dl</td>\n",
       "      <td>2024-03-17T10:45:24Z</td>\n",
       "      <td>2024-03-17T10:45:24Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Yah to sala Godi media dikhaega Nahin Sab Chor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@nasreensyed6451</td>\n",
       "      <td>2024-03-17T10:44:44Z</td>\n",
       "      <td>2024-03-17T10:44:44Z</td>\n",
       "      <td>0</td>\n",
       "      <td>üëç‚ù§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             author          published_at  \\\n",
       "0                      @dhruvrathee  2024-03-15T15:46:22Z   \n",
       "1                 @KrishnaDas-vc6vo  2024-03-17T11:16:05Z   \n",
       "2                     @PremiumCar78  2024-03-17T11:15:58Z   \n",
       "3   @VillageCookingChannelTelangana  2024-03-17T11:15:48Z   \n",
       "4                  @hafizfurqan2565  2024-03-17T11:15:44Z   \n",
       "..                              ...                   ...   \n",
       "95                 @Universalmusic5  2024-03-17T10:46:21Z   \n",
       "96                     @masoomali66  2024-03-17T10:46:06Z   \n",
       "97                @dhirajthorat6301  2024-03-17T10:45:40Z   \n",
       "98                  @AjadKhan-wh3dl  2024-03-17T10:45:24Z   \n",
       "99                 @nasreensyed6451  2024-03-17T10:44:44Z   \n",
       "\n",
       "              updated_at  like_count  \\\n",
       "0   2024-03-16T12:09:00Z        8353   \n",
       "1   2024-03-17T11:16:05Z           0   \n",
       "2   2024-03-17T11:15:58Z           0   \n",
       "3   2024-03-17T11:15:48Z           0   \n",
       "4   2024-03-17T11:15:44Z           0   \n",
       "..                   ...         ...   \n",
       "95  2024-03-17T10:46:21Z           2   \n",
       "96  2024-03-17T10:46:06Z           0   \n",
       "97  2024-03-17T10:45:40Z           0   \n",
       "98  2024-03-17T10:45:24Z           0   \n",
       "99  2024-03-17T10:44:44Z           0   \n",
       "\n",
       "                                              Comment  \n",
       "0   Today, is 10th Day of Fast for Sonam Wangchuk....  \n",
       "1             Why you are silent on sandeshkhali BDSK  \n",
       "2   BJP walo ki ulti ginti shuru. Ye andhbakto ko ...  \n",
       "3   i don&#39;t have words to say how much ur grea...  \n",
       "4         Very good information garet job brother ‚ù§‚ù§‚ù§  \n",
       "..                                                ...  \n",
       "95  Bhai pata nahi kyu youTube inki video ko trend...  \n",
       "96                          electoral bonds par video  \n",
       "97  Bhai Modi ke pas. black magic..hey...o..kisi k...  \n",
       "98  Yah to sala Godi media dikhaega Nahin Sab Chor...  \n",
       "99                                                 üëç‚ù§  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyCxrxZIDPNZ1Xn76a9WTACQ48wv3mLZGQI\"\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "\n",
    "request = youtube.commentThreads().list(\n",
    "    part=\"snippet\",\n",
    "    videoId=\"nV4vZo6A-Ak\",\n",
    "    maxResults=100\n",
    ")\n",
    "response = request.execute()\n",
    "\n",
    "comments = []\n",
    "\n",
    "for item in response['items']:\n",
    "    response\n",
    "    comment = item['snippet']['topLevelComment']['snippet']\n",
    "    comments.append([\n",
    "        comment['authorDisplayName'],\n",
    "        comment['publishedAt'],\n",
    "        comment['updatedAt'],\n",
    "        comment['likeCount'],\n",
    "        comment['textDisplay']\n",
    "        \n",
    "    ])\n",
    "\n",
    "df = pd.DataFrame(comments, columns=['author', 'published_at', 'updated_at', 'like_count', 'Comment'])\n",
    "df.to_csv(\"comments.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15e49608-1590-4b17-b2b3-fedc146e7c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\saiba\n",
      "[nltk_data]     noor\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Import functions for data preprocessing & data preparation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "849730e7-73bf-4318-88c2-f1c384a90591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today, is 10th Day of Fast for Sonam Wangchuk....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why you are silent on sandeshkhali BDSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BJP walo ki ulti ginti shuru. Ye andhbakto ko ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i don&amp;#39;t have words to say how much ur grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very good information garet job brother ‚ù§‚ù§‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Bhai pata nahi kyu youTube inki video ko trend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>electoral bonds par video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bhai Modi ke pas. black magic..hey...o..kisi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Yah to sala Godi media dikhaega Nahin Sab Chor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>üëç‚ù§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment\n",
       "0   Today, is 10th Day of Fast for Sonam Wangchuk....\n",
       "1             Why you are silent on sandeshkhali BDSK\n",
       "2   BJP walo ki ulti ginti shuru. Ye andhbakto ko ...\n",
       "3   i don&#39;t have words to say how much ur grea...\n",
       "4         Very good information garet job brother ‚ù§‚ù§‚ù§\n",
       "..                                                ...\n",
       "95  Bhai pata nahi kyu youTube inki video ko trend...\n",
       "96                          electoral bonds par video\n",
       "97  Bhai Modi ke pas. black magic..hey...o..kisi k...\n",
       "98  Yah to sala Godi media dikhaega Nahin Sab Chor...\n",
       "99                                                 üëç‚ù§\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"comments.csv\")\n",
    "data.columns\n",
    "data1=data.drop([\"author\",\"Unnamed: 0\",\t\"published_at\",\t\"updated_at\",\"like_count\"],axis=1)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab7220b6-8b88-4e5f-89b5-238f06d14ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\saiba\n",
      "[nltk_data]     noor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today, is 10th Day of Fast for Sonam Wangchuk....</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.5191</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why you are silent on sandeshkhali BDSK</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BJP walo ki ulti ginti shuru. Ye andhbakto ko ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i don&amp;#39;t have words to say how much ur grea...</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very good information garet job brother ‚ù§‚ù§‚ù§</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‡§ï‡§ø‡§∏ ‡§π‡§¶ ‡§§‡§ï ‡§¶‡•á‡§∂ ‡§ï‡•ã ‡§µ‡§ø‡§®‡§æ‡§∂ ‡§ï‡•Ä ‡§§‡§∞‡§´ ‡§ß‡§ï‡•á‡§≤‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à,...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dhruv thankyou so much mentioning about the Ma...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>great initiative</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Osm work dhruv</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>üáÆüá≥üëåüíØüéâ</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Positive  Negative  \\\n",
       "0  Today, is 10th Day of Fast for Sonam Wangchuk....     0.079       0.0   \n",
       "1            Why you are silent on sandeshkhali BDSK     0.000       0.0   \n",
       "2  BJP walo ki ulti ginti shuru. Ye andhbakto ko ...     0.000       0.0   \n",
       "3  i don&#39;t have words to say how much ur grea...     0.141       0.0   \n",
       "4        Very good information garet job brother ‚ù§‚ù§‚ù§     0.347       0.0   \n",
       "5  ‡§ï‡§ø‡§∏ ‡§π‡§¶ ‡§§‡§ï ‡§¶‡•á‡§∂ ‡§ï‡•ã ‡§µ‡§ø‡§®‡§æ‡§∂ ‡§ï‡•Ä ‡§§‡§∞‡§´ ‡§ß‡§ï‡•á‡§≤‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à,...     0.000       0.0   \n",
       "6  Dhruv thankyou so much mentioning about the Ma...     0.000       0.0   \n",
       "7                                   great initiative     0.804       0.0   \n",
       "8                                     Osm work dhruv     0.000       0.0   \n",
       "9                                              üáÆüá≥üëåüíØüéâ     0.000       0.0   \n",
       "\n",
       "   Neutral  Compound Sentiment  \n",
       "0    0.921    0.5191  Positive  \n",
       "1    1.000    0.0000   Neutral  \n",
       "2    1.000    0.0000   Neutral  \n",
       "3    0.859    0.6249  Positive  \n",
       "4    0.653    0.4927  Positive  \n",
       "5    1.000    0.0000   Neutral  \n",
       "6    1.000    0.0000   Neutral  \n",
       "7    0.196    0.6249  Positive  \n",
       "8    1.000    0.0000   Neutral  \n",
       "9    1.000    0.0000   Neutral  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "data1[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data1[\"Comment\"]]\n",
    "data1[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data1[\"Comment\"]]\n",
    "data1[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data1[\"Comment\"]]\n",
    "data1['Compound'] = [sentiments.polarity_scores(i)[\"compound\"] for i in data1[\"Comment\"]]\n",
    "score = data1[\"Compound\"].values\n",
    "sentiment = []\n",
    "for i in score:\n",
    "    if i >= 0.05 :\n",
    "        sentiment.append('Positive')\n",
    "    elif i <= -0.05 :\n",
    "        sentiment.append('Negative')\n",
    "    else:\n",
    "        sentiment.append('Neutral')\n",
    "data1[\"Sentiment\"] = sentiment\n",
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5aefc89-3ae3-4cdb-86c7-11d0e007f28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today, is 10th Day of Fast for Sonam Wangchuk....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why you are silent on sandeshkhali BDSK</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BJP walo ki ulti ginti shuru. Ye andhbakto ko ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i don&amp;#39;t have words to say how much ur grea...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very good information garet job brother ‚ù§‚ù§‚ù§</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Bhai pata nahi kyu youTube inki video ko trend...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>electoral bonds par video</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bhai Modi ke pas. black magic..hey...o..kisi k...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Yah to sala Godi media dikhaega Nahin Sab Chor...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>üëç‚ù§</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment Sentiment\n",
       "0   Today, is 10th Day of Fast for Sonam Wangchuk....  Positive\n",
       "1             Why you are silent on sandeshkhali BDSK   Neutral\n",
       "2   BJP walo ki ulti ginti shuru. Ye andhbakto ko ...   Neutral\n",
       "3   i don&#39;t have words to say how much ur grea...  Positive\n",
       "4         Very good information garet job brother ‚ù§‚ù§‚ù§  Positive\n",
       "..                                                ...       ...\n",
       "95  Bhai pata nahi kyu youTube inki video ko trend...   Neutral\n",
       "96                          electoral bonds par video   Neutral\n",
       "97  Bhai Modi ke pas. black magic..hey...o..kisi k...   Neutral\n",
       "98  Yah to sala Godi media dikhaega Nahin Sab Chor...   Neutral\n",
       "99                                                 üëç‚ù§   Neutral\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.drop([\"Positive\",\"Negative\",\"Neutral\",\"Compound\"],axis=1)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "257a86c0-b1f2-4f72-9323-52c3d08ffb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dddcee42-ed5f-4db6-85d7-89edd999c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer() \n",
    "snowball_stemer = SnowballStemmer(language=\"english\")\n",
    "lzr = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a63ab519-cd10-4dec-9a90-35719337f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):   \n",
    "    # convert text into lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove new line characters in text\n",
    "    text = re.sub(r'\\n',' ', text)\n",
    "    \n",
    "    # remove punctuations from text\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), \"\", text)\n",
    "    \n",
    "    # remove references and hashtags from text\n",
    "    text = re.sub(\"^a-zA-Z0-9$,.\", \"\", text)\n",
    "    \n",
    "    # remove multiple spaces from text\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # remove special characters from text\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n",
    "    \n",
    "    # stemming using porter stemmer from nltk package - msh a7sn 7aga - momken: lancaster, snowball\n",
    "    # text=' '.join([porter_stemmer.stem(word) for word in word_tokenize(text)])\n",
    "    # text=' '.join([lancaster_stemmer.stem(word) for word in word_tokenize(text)])\n",
    "    # text=' '.join([snowball_stemer.stem(word) for word in word_tokenize(text)])\n",
    "    \n",
    "    # lemmatizer using WordNetLemmatizer from nltk package\n",
    "    text=' '.join([lzr.lemmatize(word) for word in word_tokenize(text)])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f6dcce0-94aa-4df3-b24c-067e9416203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\saiba\n",
      "[nltk_data]     noor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "data_copy = data2.copy()\n",
    "data_copy.Comment = data_copy.Comment.apply(lambda text: text_processing(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "508350b8-750e-4003-9f5f-846291d1ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79dba4cc-549e-4602-bec3-f56b346c8627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>today 10th day fast sonam wangchuk subscribe c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>silent sandeshkhali bdsk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bjp walo ki ulti ginti shuru ye andhbakto ko m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>don39t word say much ur great collect news art...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good information garet job brother</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‡§ï ‡§∏ ‡§π‡§¶ ‡§§‡§ï ‡§¶ ‡§∂ ‡§ï ‡§µ ‡§® ‡§∂ ‡§ï ‡§§‡§∞‡§´ ‡§ß‡§ï ‡§≤ ‡§ú ‡§∞‡§π ‡§π ‡§ú ‡§®‡§® ‡§ï...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dhruv thankyou much mentioning manipur</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>great initiative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>osm work dhruv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment\n",
       "0  today 10th day fast sonam wangchuk subscribe c...          2\n",
       "1                           silent sandeshkhali bdsk          1\n",
       "2  bjp walo ki ulti ginti shuru ye andhbakto ko m...          1\n",
       "3  don39t word say much ur great collect news art...          2\n",
       "4                 good information garet job brother          2\n",
       "5  ‡§ï ‡§∏ ‡§π‡§¶ ‡§§‡§ï ‡§¶ ‡§∂ ‡§ï ‡§µ ‡§® ‡§∂ ‡§ï ‡§§‡§∞‡§´ ‡§ß‡§ï ‡§≤ ‡§ú ‡§∞‡§π ‡§π ‡§ú ‡§®‡§® ‡§ï...          1\n",
       "6             dhruv thankyou much mentioning manipur          1\n",
       "7                                   great initiative          2\n",
       "8                                     osm work dhruv          1\n",
       "9                                                             1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = {\n",
    "    'Sentence':data_copy.Comment,\n",
    "    'Sentiment':data_copy['Sentiment']\n",
    "}\n",
    "\n",
    "processed_data = pd.DataFrame(processed_data)\n",
    "processed_data.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec442703-fc70-44c7-9893-f8b702e0ba6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "1    52\n",
       "2    35\n",
       "0    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dbe4ae7-eb57-4239-be79-2c3b93ce8a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neutral = processed_data[(processed_data['Sentiment']==1)] \n",
    "df_negative = processed_data[(processed_data['Sentiment']==0)]\n",
    "df_positive = processed_data[(processed_data['Sentiment']==2)]\n",
    "\n",
    "# upsample minority classes\n",
    "df_negative_upsampled = resample(df_negative, \n",
    "                                 replace=True,    \n",
    "                                 n_samples= 205, \n",
    "                                 random_state=42)  \n",
    "\n",
    "df_neutral_upsampled = resample(df_neutral, \n",
    "                                 replace=True,    \n",
    "                                 n_samples= 205, \n",
    "                                 random_state=42)  \n",
    "\n",
    "\n",
    "# Concatenate the upsampled dataframes with the neutral dataframe\n",
    "final_data = pd.concat([df_negative_upsampled,df_neutral_upsampled,df_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0f402da-1c69-4290-955d-35bf93122a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "0    205\n",
       "1    205\n",
       "2     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04f8fd0a-af9e-4c29-abd1-ca11514e1d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shameless medium',\n",
       " 'dhruv rathee bad working modi bjp party party bad bad',\n",
       " 'bhai ek video delhi liquor scam aur sandeshkhali ke bare mein bhi video banao',\n",
       " 'maratha protest mumbai',\n",
       " 'aap bhi tu palestine aur israel ki war par koi awaz nahi utha rahe jab ukraine aur russia ki war chal rahi thi jab ye 3 4 video bana chuky thy ye secularism k naam pe sirf paisa chap rahe hain logon ko dikha k dekho main main secularism ko manta hoaur bhi hain youtuber jo secularism ko dhal bana kar apna business chalate hain doubt aap ka content best aur knowledgeable huta hai aap ne jab haldwani main protest ho raha tha jab video kyoun nahi banaijab maharashtra main kuch logon ne masjid main juhss kar muslim ko peeta berami se tab video kyoun nahi aaijab dusre han protest huta ya kuch huta hai tu badi jaldi video bana dete hoaisa kyon answer itho sake tu']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for sentence in final_data['Sentence']:\n",
    "    corpus.append(sentence)\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79e7983d-9da6-4a16-97cf-e3cc0f22ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = final_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e0513-069d-493c-b75a-bd92a878271f",
   "metadata": {},
   "source": [
    "### from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64417c2c-b424-417c-8d61-a47192c526ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61,  0,  0],\n",
       "       [ 6, 54,  3],\n",
       "       [ 3,  1,  6]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "340e3460-258b-48ca-926b-36fb7299be99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9029850746268657\n"
     ]
    }
   ],
   "source": [
    "nb_score = accuracy_score(y_test, y_pred)\n",
    "print('accuracy',nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80b847-5ded-42c6-802e-3a40320a2e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
